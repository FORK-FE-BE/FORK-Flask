from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage
import json
import logging
llm = ChatOpenAI(model="gpt-4o")
logger = logging.getLogger(__name__)

def safe_parse_followups(raw: str):
    try:
        parsed = json.loads(raw)
        if isinstance(parsed, list) and len(parsed) == 1 and isinstance(parsed[0], str):
            nested = json.loads(parsed[0])
            if isinstance(nested, list):
                return nested
        if isinstance(parsed, list):
            return parsed
    except json.JSONDecodeError:
        pass

    fallback = [line.strip("â€¢-â€“â€” []\",") for line in raw.splitlines() if line.strip()]
    return fallback

def safe_parse_followups(raw: str):
    try:
        parsed = json.loads(raw)
        if isinstance(parsed, list) and len(parsed) == 1 and isinstance(parsed[0], str):
            nested = json.loads(parsed[0])
            if isinstance(nested, list):
                return nested
        if isinstance(parsed, list):
            return parsed
    except json.JSONDecodeError:
        pass

    fallback = [line.strip("â€¢-â€“â€” []\",") for line in raw.splitlines() if line.strip()]
    return fallback

def generate_followups(state: dict):
    try:
        prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: "{state['message']}"

ì´ ì§ˆë¬¸ê³¼ ê´€ë ¨í•´ ì‚¬ìš©ìê°€ ë” íƒìƒ‰í•  ìˆ˜ ìˆëŠ” ì£¼ì œ í‚¤ì›Œë“œë¥¼ 3ê°€ì§€ ì œì•ˆí•´ì¤˜.
- ë°˜ë“œì‹œ ~~ì¶”ì²œ í•´ì¤˜ ë¼ëŠ” í‚¤ì›Œë“œë¡œ ëë‚ ê²ƒ
- ë°˜ë“œì‹œ JSON ë°°ì—´ë¡œë§Œ ì¶œë ¥í•  ê²ƒ
- ì„¤ëª…, ì¤„ë°”ê¿ˆ, ë”°ì˜´í‘œ, íŠ¹ìˆ˜ê¸°í˜¸ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆ

"""

        result = llm.invoke([HumanMessage(content=prompt)])
        raw = result.content.strip()

        followups = safe_parse_followups(raw)

        logger.info("ğŸ“Œ íŒŒìƒ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ: %s", followups)
        return {**state, "followups": followups}

    except Exception as e:
        logger.exception("âŒ [generate_followups] ì˜¤ë¥˜ ë°œìƒ: %s", e)
        return {**state, "followups": []}