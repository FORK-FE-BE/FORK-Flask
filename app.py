import os
import json
import logging
from flask import Flask, request, jsonify
from dotenv import load_dotenv
import openai

# âœ… ìµœì‹  LangChain êµ¬ì¡°
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_qdrant import Qdrant
from langchain.retrievers.multi_query import MultiQueryRetriever
from qdrant_client import QdrantClient

from geopy.distance import geodesic
from langchain_core.messages import HumanMessage

# ====================
# ğŸ› ï¸ Logging ì„¤ì •
# ====================
logging.basicConfig(
    level=logging.INFO,
    format='[%(asctime)s] %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ====================
# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
# ====================
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ====================
# ğŸš€ Flask ì•± ì‹œì‘
# ====================
app = Flask(__name__)

# ====================
# ğŸ§  Qdrant + LangChain ì„¤ì •
# ====================
qdrant_client = QdrantClient(
    url=os.getenv("QDRANT_URL"),
    api_key=os.getenv("QDRANT_API_KEY")
)

embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

qdrant_store = Qdrant(
    client=qdrant_client,
    collection_name="menus",
    embeddings=embedding_model,
    content_payload_key="page_content",
)

llm = ChatOpenAI(model="gpt-4o")

multi_query_retriever = MultiQueryRetriever.from_llm(
    retriever=qdrant_store.as_retriever(search_kwargs={"k": 5}),
    llm=llm
)

# ====================
# ğŸ” íŒŒìƒ ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜
# ====================
def generate_followup_queries_with_llm(message, llm):
    prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: "{message}"

ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ì‚¬ìš©ìê°€ ê´€ì‹¬ ê°€ì§ˆ ë§Œí•œ ê´€ë ¨ ì¶”ê°€ ì§ˆë¬¸ì„ 3ê°€ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ë§Œë“¤ì–´ì¤˜.
ê° ì§ˆë¬¸ì€ í•œ ì¤„ë¡œ, ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì—†ì´ ë¬¸ìì—´ ë°°ì—´ë¡œ ìƒì„±í•´ì¤˜.
"""
    response = llm.invoke([HumanMessage(content=prompt)])
    content = response.content.strip()

    # JSON í˜•ì‹ì¼ ê²½ìš° ì²˜ë¦¬
    try:
        parsed = json.loads(content)
        if isinstance(parsed, list):
            return [q.strip() for q in parsed]
    except json.JSONDecodeError:
        pass

    # ì•„ë‹ ê²½ìš° ê°œí–‰ ê¸°ì¤€ ì²˜ë¦¬
    return [line.strip("â€¢-â€” ") for line in content.split("\n") if line.strip()]

# ====================
# ğŸ¯ ì¶”ì²œ API
# ====================
@app.route("/recommend", methods=["POST"])
def recommend():
    data = request.json
    message = data.get("message")
    lat = data.get("latitude")
    lon = data.get("longitude")
    restrictions = data.get("restrictions", [])
    previousResults = data.get("previousResults", [])

    logger.info(f"ğŸ“¥ ì‚¬ìš©ì ë©”ì‹œì§€: {message}")
    logger.info(f"ğŸ“ ìœ„ì¹˜: ({lat}, {lon})")
    logger.info(f"â›” ì œí•œ ìŒì‹: {restrictions}")
    logger.info(f"ğŸ” ì´ì „ ê²°ê³¼: {previousResults}")

    def is_within_radius(user_lat, user_lon, target_lat, target_lon, radius_km=10):
        try:
            return geodesic((user_lat, user_lon), (target_lat, target_lon)).km <= radius_km
        except Exception as e:
            logger.warning(f"â— ê±°ë¦¬ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return False

    try:
        docs = multi_query_retriever.get_relevant_documents(message)
        logger.info(f"ğŸ” ë¬¸ì„œ ê²€ìƒ‰ ê²°ê³¼ ìˆ˜: {len(docs)}")

        ENABLE_FILTER = False

        filtered_results = []
        for doc in docs:
            meta = getattr(doc, "metadata", {})
            if not meta:
                continue

            if ENABLE_FILTER:
                loc = meta.get("location")
                if loc:
                    if not is_within_radius(lat, lon, loc.get("lat"), loc.get("lon"), 3):
                        continue

            menu_name = meta.get("menu", "").lower()
            if any(res.lower() in menu_name for res in restrictions):
                continue

            filtered_results.append(meta)

        logger.info(f"âœ… í•„í„°ë§ ê²°ê³¼ ìˆ˜: {len(filtered_results)}")

        results = [{
            "menuId": p.get("menuId"),
            "menu": p.get("menu"),
            "category": p.get("category"),
            "price": p.get("price"),
            "restaurant": p.get("restaurant"),
            "restaurantId": p.get("restaurantId"),
            "address": p.get("address"),
            "hasAR": p.get("hasAR"),
            "hasCoupon": p.get("hasCoupon"),
            "location": p.get("location"),
            "description": p.get("description"),
            "page_content": p.get("page_content"),
        } for p in filtered_results]

        logger.info("ğŸ½ï¸ ìµœì¢… ì¶”ì²œ ê²°ê³¼:\n%s", json.dumps(results, ensure_ascii=False, indent=2))

        gpt_response = openai.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ìŒì‹ ì¶”ì²œ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì¤˜."},
                {"role": "user", "content": f"ë‹¤ìŒ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì†Œê°œí•´ì¤˜:\n{json.dumps(results, ensure_ascii=False)}"}
            ],
            temperature=0.7
        )
        natural_response = gpt_response.choices[0].message.content

        followups = generate_followup_queries_with_llm(message, llm)

        return jsonify({
            "recommendation": results,
            "response": natural_response,
            "followUpSuggestions": followups
        })

    except Exception as e:
        logger.exception("âŒ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ")
        return jsonify({"error": f"ì¶”ì²œ ì‹¤íŒ¨: {str(e)}"}), 500

# ====================
# ğŸ§ª ì•± ì‹¤í–‰
# ====================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000, debug=True)
