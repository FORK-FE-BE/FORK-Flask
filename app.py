import os
import json
import logging
from flask import Flask, request, jsonify
from dotenv import load_dotenv
import openai
from langchain_community.chat_models import ChatOpenAI
from langchain_community.vectorstores import Qdrant
from langchain.embeddings import OpenAIEmbeddings
from langchain.retrievers.multi_query import MultiQueryRetriever
from qdrant_client import QdrantClient
from geopy.distance import geodesic
from langchain_core.messages import HumanMessage

# ====================
# ğŸ› ï¸ Logging ì„¤ì •
# ====================
logging.basicConfig(
    level=logging.INFO,  # DEBUGë¡œ ë°”ê¾¸ë©´ ë” ìƒì„¸ ë¡œê·¸ í™•ì¸ ê°€ëŠ¥
    format='[%(asctime)s] %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)

# ====================
# ğŸ” í™˜ê²½ ë³€ìˆ˜ ë¡œë”©
# ====================
load_dotenv()
openai.api_key = os.getenv("OPENAI_API_KEY")

# ====================
# ğŸš€ Flask ì•± ì‹œì‘
# ====================
app = Flask(__name__)

# ====================
# ğŸ§  Qdrant + LangChain ì„¤ì •
# ====================
qdrant_client = QdrantClient(
    url=os.getenv("QDRANT_URL"),
    api_key=os.getenv("QDRANT_API_KEY")
)
embedding_model = OpenAIEmbeddings(model="text-embedding-3-small")

qdrant_store = Qdrant(
    client=qdrant_client,
    collection_name="menus",
    embeddings=embedding_model,
    content_payload_key="page_content",   # ê²€ìƒ‰ í…ìŠ¤íŠ¸ ê¸°ì¤€ key
)

# âœ… LLM ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì „ì—­ìœ¼ë¡œ ì„ ì–¸í•´ì„œ ì¬ì‚¬ìš©
llm = ChatOpenAI(model="gpt-4o")

multi_query_retriever = MultiQueryRetriever.from_llm(
    retriever=qdrant_store.as_retriever(search_kwargs={"k": 5}),
    llm=llm
)



# ====================
# ğŸ” ì¶”ê°€ ì§ˆë¬¸ ìƒì„± í•¨ìˆ˜
# ====================
def generate_followup_queries_with_llm(message, llm):
    prompt = f"""
ì‚¬ìš©ì ì§ˆë¬¸: "{message}"

ìœ„ ì§ˆë¬¸ì— ëŒ€í•´ ì‚¬ìš©ìê°€ ê´€ì‹¬ ê°€ì§ˆ ë§Œí•œ ê´€ë ¨ ì¶”ê°€ ì§ˆë¬¸ì„ 3ê°€ì§€ ìì—°ìŠ¤ëŸ½ê²Œ ë§Œë“¤ì–´ì¤˜.
ê° ì§ˆë¬¸ì€ í•œ ì¤„ë¡œ, ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ì—†ì´ ë¬¸ìì—´ ë°°ì—´ë¡œ ìƒì„±í•´ì¤˜.
ì˜ˆì‹œ:
- ì´ ì§‘ì˜ ë‹¤ë¥¸ ë©”ë‰´ë„ ì•Œë ¤ì¤˜
- ë¹„ìŠ·í•œ ë©”ë‰´ë¥¼ ë‹¤ë¥¸ ì‹ë‹¹ì—ì„œë„ ì¶”ì²œí•´ì¤˜
- ê·¼ì²˜ ë‹¤ë¥¸ ì¤‘ì‹ë‹¹ë„ ì°¾ì•„ì¤˜
"""
    response = llm.invoke([HumanMessage(content=prompt)])
    followups = [line.strip("â€¢-â€¢â€” ") for line in response.content.strip().split("\n") if line.strip()]
    return followups



# ====================
# ğŸ¯ Api: ì¶”ì²œ
# ====================
@app.route("/recommend", methods=["POST"])
def recommend():
    data = request.json
    message = data.get("message")
    lat = data.get("latitude")
    lon = data.get("longitude")
    restrictions = data.get("restrictions", [])
    previousResults = data.get("previousResults", [])

    logger.info(f"ğŸ“¥ ì‚¬ìš©ì ë©”ì‹œì§€: {message}")
    logger.info(f"ğŸ“ ì‚¬ìš©ì ìœ„ì¹˜: ({lat}, {lon})")
    logger.info(f"â›” ì œí•œ ìŒì‹: {restrictions}")
    logger.info(f"ğŸ” ì´ì „ ì¶”ì²œ ê²°ê³¼: {previousResults}")

    def is_within_radius(user_lat, user_lon, target_lat, target_lon, radius_km=10):
        try:
            return geodesic((user_lat, user_lon), (target_lat, target_lon)).km <= radius_km
        except Exception as e:
            logger.warning(f"â— ê±°ë¦¬ ê³„ì‚° ì‹¤íŒ¨: {e}")
            return False
    
    try:

        # ë©€í‹°ì¿¼ë¦¬ ê²€ìƒ‰
        docs = multi_query_retriever.get_relevant_documents(message)
        logger.info(f"ğŸ” ê²€ì¶œëœ ë¬¸ì„œ ìˆ˜: {len(docs)}")

        ENABLE_FILTER = False  # ê±°ë¦¬ í•„í„° ì‚¬ìš© ì—¬ë¶€ (Trueì¼ ê²½ìš° í™œì„±í™”)

        # ê±°ë¦¬ í•„í„°ë§ + ì œí•œ ìŒì‹ í•„í„° (ì˜ˆì‹œ: ì œí•œ ìŒì‹ ì œì™¸)
        filtered_results = []
        for doc in docs:
            meta = getattr(doc, "metadata", {})
            if not meta:
                logger.warning(f"doc.metadata ë¹„ì–´ìˆìŒ, doc: {doc}")
                continue

            # ê±°ë¦¬ í•„í„°
            if ENABLE_FILTER:
                loc = meta.get("location")
                if loc:
                    target_lat = loc.get("lat")
                    target_lon = loc.get("lon")
                    if (
                        target_lat is not None
                        and target_lon is not None
                        and is_within_radius(lat, lon, target_lat, target_lon, radius_km=3)
                    ):
                        pass
                    else:
                        continue
                else:
                    continue  # ìœ„ì¹˜ê°€ ì—†ìœ¼ë©´ í•„í„°ì—ì„œ ì œì™¸

            # ì œí•œ ìŒì‹ í¬í•¨ ì—¬ë¶€ ì²´í¬ (ì˜ˆ: ë©”ë‰´ëª…ì— ì œí•œ ë‹¨ì–´ê°€ í¬í•¨ë˜ë©´ ì œì™¸)
            menu_name = meta.get("menu", "").lower()
            if any(res.lower() in menu_name for res in restrictions):
                continue

            filtered_results.append(meta)

        logger.info(f"âœ… í•„í„°ë§ í›„ ê²°ê³¼ ìˆ˜: {len(filtered_results)}")

        # ì¶”ì²œ ê²°ê³¼ í¬ë§· ë³€í™˜
        results = []
        for p in filtered_results:
            results.append({
                "menuId": p.get("menuId"),
                "menu": p.get("menu"),
                "category": p.get("category"),
                "price": p.get("price"),
                "restaurant": p.get("restaurant"),
                "restaurantId": p.get("restaurantId"),
                "address": p.get("address"),
                "hasAR": p.get("hasAR"),
                "hasCoupon": p.get("hasCoupon"),
                "location": p.get("location"),
                "description": p.get("description"),
                "page_content": p.get("page_content"),
            })

        logger.info("ğŸ½ï¸ ìµœì¢… ì¶”ì²œ ê²°ê³¼:\n%s", json.dumps(results, ensure_ascii=False, indent=2))

        # ìì—°ì–´ ì‘ë‹µ ìƒì„±
        gpt_response = openai.ChatCompletion.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ìŒì‹ ì¶”ì²œ ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ì„¤ëª…í•´ì¤˜."},
                {"role": "user", "content": f"ë‹¤ìŒ ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í•œ ë¬¸ì¥ìœ¼ë¡œ ì†Œê°œí•´ì¤˜:\n{json.dumps(results, ensure_ascii=False)}"}
            ]
        )
        natural_response = gpt_response.choices[0].message["content"]
        logger.info("ğŸ—£ï¸ ìì—°ì–´ ì‘ë‹µ ìƒì„± ì™„ë£Œ: %s", natural_response)
        
        # ğŸ’¬ ì¶”ê°€ ì§ˆë¬¸ ìƒì„±
        followups = generate_followup_queries_with_llm(message, llm)
        logger.info("ğŸ’¡ íŒŒìƒ ì§ˆë¬¸: %s", followups)
        
        return jsonify({
            "recommendation": results,
            "response": natural_response,
            "followUpSuggestions": followups  #íŒŒìƒ ì§ˆë¬¸
        })

    except Exception as e:
        logger.exception("âŒ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ")
        return jsonify({"error": f"ì¶”ì²œ ì‹¤íŒ¨: {str(e)}"}), 500


# ====================
# ğŸ§ª ì•± ì‹¤í–‰ ì‹œì‘
# ====================
if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8000, debug=True)
